# PII-Scrubber
A model to automate the removal of Personally Identifiable Information (PII) entities from text. 

## Background 
Student writing is an invaluable asset for learning science and educational research. Essays are a key means of studying student opinions, and have been used by researchers to study complex issues such as how writing characteristics affect teachers’ evaluations [1], peer feedback patterns and their impact on student writing [2], and identification of students’ learning challenges [3]. A common challenge in releasing open educational datasets of student essays for studies is the presence of personally identifiable information (PII). PIIs may reveal sensitive personal details such as names, ID numbers, phone numbers, email addresses, and even physical addresses [4], and pose significant risks to student privacy. 

Currently, manually reviewing essays to remove this information and prevent PPI leakage is the most reliable approach, but it is inefficient and cost-ineffective [4]. With recent rapid developments in deep learning and natural language processing (NLP), the PII screening process can be automated using NLP techniques and large language models (LLMs). In this project, we attempt to automate the identification process of PII entities from student writing samples.

## Data Decription
The dataset used is provided on Kaggle for a PII Data Detection competition hosted by The Learning Agency Lab at Vanderbilt University [4]. The dataset contains 22,000 student essay samples, among which about 30% are publicly available for training while the remaining are reserved for testing. For each sample, the full text, tokenized text, whitespace indicators, and PII labels are provided. PIIs in this dataset can be a student name, an email, a username, a student ID, a phone number, a personal URL, or a street address, and each of these is assigned a unique class label, prefixed with “B-” to signal it as a PII. Following conventions of the BIO (Beginning, Inner, Outer) format, all non-PIIs are labeled with “O”, and continuation entities are labeled with “I”. Since the amount of training data is limited, we will consider using another supplementary open-sourced PII dataset generated by LLMs from the Kaggle community, which is provided specifically for this competition and given in the same format [5]. This external dataset contains another 4,500 synthesized samples.

## References 
- [1] Freedman, S.W. (1979) ‘How characteristics of Student Essays Influence Teachers’ evaluations.’, Journal of Educational Psychology, 71(3), pp. 328–338. doi:10.1037/0022-0663.71.3.328.
- [2] Kerman, N.T. et al. (2022) ‘Online peer feedback patterns of success and failure in argumentative essay writing’, Interactive Learning Environments, pp. 1–13. doi:10.1080/10494820.2022.2093914.
- [3] Simamora, R.M. (2020) ‘The challenges of online learning during the COVID-19 pandemic: An essay analysis of performing arts education students’, Studies in Learning and Teaching, 1(2), pp. 86–103. doi:10.46627/silet.v1i2.38. 
- [4] The Learning Agency Lab - PII Data Detection. Kaggle. Available at: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/data
- [5] Moth, “PII: External dataset,” Kaggle, https://www.kaggle.com/datasets/alejopaullier/pii-external-dataset/data (accessed Feb. 21, 2024). 
